{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> Linear Regression Case Study\n",
    "</center>\n",
    "\n",
    "### Steps for Regression Modeling:\n",
    "1. Business problem definition - One of major automobile company would like to design new product which can improve the sales. Inorder to define the product, they want to understand/identify drivers for the sales (what are the factors driving sales) and Predicting sales of different car models given driving factors. \n",
    "2. Convert business problem into statistical problem  sales = F(sales attributes, product features, marketing info etc.)\n",
    "3. Finding the right technique - Since it is predicting value (Regression Problem) problem so we can use OLS as one of the technique. We can also use other techniques like Decision Trees, Ensemble learning, KNN, SVM, ANN etc.\n",
    "4. Data colletion(Y, X) - Identify the sources of information and collect the data\n",
    "5. Consolidate the data - aggregate and consolidate the data at Model level/customer level/store level depends on business problem\n",
    "6. Data preparation for modeling (create data audit report to identify the steps to perform as part of data preparation)\n",
    "    a. missing value treatment\n",
    "    b. outlier treatment\n",
    "    c. dummy variable creation\n",
    "7. Variable creation by using transformation and derived variable creation.\n",
    "8. Basic assumptions (Normality, linearity, no outliers, homoscadasticity, no pattern in residuals, no auto correlation etc)\n",
    "9. Variable reduction techniques (removing multicollinerity with the help of FA/PCA, correlation matrics, VIF)\n",
    "10. Create dev and validation data sets (50:50 if you have more data else 70:30 or 80:20)\n",
    "11. Modeling on dev data set (identify significant variables, model interpretation, check the signs and coefficients, multi-collinierity check, measures of good neess fit, final mathematical equation etc)\n",
    "12. validating on validation data set (check the stability of model, scoring, decile analysis, cross validation etc.)\n",
    "13. Output interpretation and derive insights (understand the limitations of the model and define strategy to implementation)\n",
    "14. convert statistical solution into business solutions (implementation, model monitoring etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas_profiling \n",
    "import scipy.stats as stats\n",
    "import sklearn as sk\n",
    "import statsmodels as sm\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 6, 4\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#from sklearn.preprocessing import imputation\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.linear_model import  Lasso, Ridge, ElasticNet\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.manifold import TSNE\n",
    "#from sklearn.cluster import KMeans, DBSCAN\n",
    "#from sklearn.svm import SVR\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data audit Report for continuous variables\n",
    "def continuous_var_summary(x):\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.sum(), x.mean(), x.median(),  \n",
    "                      x.std(), x.var(), x.min(), x.quantile(0.01), x.quantile(0.05),\n",
    "                          x.quantile(0.10),x.quantile(0.25),x.quantile(0.50),x.quantile(0.75), \n",
    "                              x.quantile(0.90),x.quantile(0.95), x.quantile(0.99),x.max()], \n",
    "                  index = ['N', 'NMISS', 'SUM', 'MEAN','MEDIAN', 'STD', 'VAR', 'MIN', 'P1', \n",
    "                               'P5' ,'P10' ,'P25' ,'P50' ,'P75' ,'P90' ,'P95' ,'P99' ,'MAX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data audit Report for categorical variables\n",
    "def categorical_var_summary(x):\n",
    "    Mode = x.value_counts().sort_values(ascending = False)[0:1].reset_index()\n",
    "    return pd.Series([x.count(), x.isnull().sum(), Mode.iloc[0, 0], Mode.iloc[0, 1], \n",
    "                          round(Mode.iloc[0, 1] * 100/x.count(), 2)], \n",
    "                  index = ['N', 'NMISS', 'MODE', 'FREQ', 'PERCENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value imputation for categorical and continuous variables\n",
    "def missing_imputation(x, stats = 'mean'):\n",
    "    if (x.dtypes == 'float64') | (x.dtypes == 'int64'):\n",
    "        x = x.fillna(x.mean()) if stats == 'mean' else x.fillna(x.median())\n",
    "    else:\n",
    "        x = x.fillna(x.mode())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An utility function to create dummy variable\n",
    "def create_dummies(df, colname):\n",
    "    col_dummies = pd.get_dummies(df[colname], prefix = colname, drop_first = True)\n",
    "    df = pd.concat([df, col_dummies], axis = 1)\n",
    "    df.drop(colname, axis = 1, inplace = True )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('D:/Sampledata/Car_sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling using pandas profiling\n",
    "report = pandas_profiling.ProfileReport(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the file as html\n",
    "# screen the variables to get rid of unuseful variable sin the begining or\n",
    "# make a note of potential variables for model refinement\n",
    "report.to_file(output_file = 'profilereport.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type conversion in case variables are not of proper type : Not required in this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate categorical and continuous variables\n",
    "cars_conti_vars = cars.loc[:, (cars.dtypes == 'float64') | (cars.dtypes == 'int64')]\n",
    "cars_cat_vars = cars.loc[:, (cars.dtypes == 'object')]\n",
    "\n",
    "# Simper way of doing:\n",
    "# cars_conti_vars = cars.select_dtypes(include = ['float64', 'int64'])\n",
    "# car_sales_cat = cars.select_dtypes(include = ['object'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# reference code\n",
    "def fn_name(x, y):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# reference code\n",
    "df.apply(fn_name)\n",
    "df.apply(lambda x: fn_name(x))\n",
    "\n",
    "y = 10\n",
    "df.apply(lambda x: fn_name(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate of .describe() for continuous variables\n",
    "cars_conti_vars.apply(continuous_var_summary).T.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate of .describe() for categorical variables\n",
    "cars_cat_vars.apply(categorical_var_summary).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_conti_vars = cars_conti_vars.apply(lambda x: x.clip(lower = x.dropna().quantile(0.01), upper = x.quantile(0.99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_conti_vars.apply(continuous_var_summary).T.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_conti_vars = cars_conti_vars.apply(missing_imputation)\n",
    "cars_cat_vars = cars_cat_vars.apply(missing_imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_conti_vars.apply(continuous_var_summary).T.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical features\n",
    "\n",
    "scikit-learn expects all features to be numeric. So how do we include a categorical feature in our model?\n",
    "\n",
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding (0/1)\n",
    "\n",
    "What are the categorical features in our dataset?\n",
    "\n",
    "- **Ordered categories:** weather (already encoded with sensible numeric values)\n",
    "- **Unordered categories:** season (needs dummy encoding), holiday (already dummy encoded), workingday (already dummy encoded)\n",
    "\n",
    "For season, we can't simply leave the encoding as 1 = spring, 2 = summer, 3 = fall, and 4 = winter, because that would imply an **ordered relationship**. Instead, we create **multiple dummy variables:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Steps to be followed to create dummy variables:\n",
    "-----------------------------------------------------------------------------------------------\n",
    "1. use pd.get_dummies() method to create dummy varaibles for each value inside the variable\n",
    "2. drop any one variable from the dummy variables to avoid multicolinearity\n",
    "3. concat the dummy data with the original dataset\n",
    "4. drop the variable from which dummy variable has been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of all the categories of the variable\n",
    "cars_cat_vars.Manufacturer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the useful categorical variables\n",
    "cars_cat_vars = cars[['Manufacturer', 'Vehicle_type']]\n",
    "\n",
    "# for c_feature in categorical_features\n",
    "for c_feature in ['Manufacturer', 'Vehicle_type']:\n",
    "    cars_cat_vars[c_feature] = cars_cat_vars[c_feature].astype('category')\n",
    "    cars_cat_vars = create_dummies(cars_cat_vars, c_feature)\n",
    "    \n",
    "# see the data in the output\n",
    "#cars_cat_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_new = pd.concat([cars_conti_vars, cars_cat_vars], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assumptions check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very first assumtion is that all the variables should be normally distributed, however that can't be possible\n",
    "# However we have to be atleast strict about the dependant Y variable\n",
    "\n",
    "# Distribution of variables\n",
    "sns.distplot(cars_new.Sales_in_thousands)\n",
    "plt.show()\n",
    "# this distribution is highly skewed\n",
    "\n",
    "# Notes:\n",
    "#-----------------------------------------------------\n",
    "# 1. if we get skewed data, then we have to transform the data and there are multiple methods to go about it\n",
    "# 2. most commonly used and which works on most of the data is log transformation\n",
    "# 3. Ideally we can do this for each of the dependant variable as well, \n",
    "#    however it will depend on amount of data and the amount of analytical rigour\n",
    "# 4. In no case we can proceed if dependant variable is not normal/near to normal distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: good practice is to take the log of the data plus 1, bcoz we don't have log of zero defined\n",
    "# In thios data its not required as sales are always greater than zero\n",
    "\n",
    "# apply log transformation: log is rescalling the data and making the distribution normal\n",
    "cars_new['ln_sales_in_thousands'] = np.log(cars_new['Sales_in_thousands'])\n",
    "\n",
    "# Distribution of variables\n",
    "sns.distplot(cars_new.ln_sales_in_thousands)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearity: correlation matrix (ranges from 1 to -1)\n",
    "corrm = cars_new.corr()\n",
    "corrm.to_csv('corrm.csv')\n",
    "corrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize correlation matrix in Seaborn using a heatmap\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.heatmap(cars_new.corr())\n",
    "\n",
    "# fuel efficiency vs fuel capacity\n",
    "# Curb weight vs Engine Size\n",
    "\n",
    "# in case we can't make any concrete decision looking at the variables; we can also check on the VAR of \n",
    "# the variables into consideration e.g Curb weight vs Wheel base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the variables based low correlation with Y\n",
    "cars_new.drop(['Curb_weight', 'Fuel_capacity', 'Manufacturer_BMW', 'Manufacturer_Buick', 'Manufacturer_Jeep', \n",
    "        'Manufacturer_Cadillac', 'Manufacturer_Chevrolet', 'Manufacturer_Chrysler', 'Manufacturer_Hyundai', \n",
    "               'Manufacturer_Infiniti', 'Manufacturer_Jaguar', 'Manufacturer_Lincoln','Manufacturer_Mercury',\n",
    "                   'Manufacturer_Oldsmobile', 'Manufacturer_Pontiac', 'Manufacturer_Saab', 'Manufacturer_Saturn',\n",
    "                       'Manufacturer_Subaru','Manufacturer_Volkswagen', 'Manufacturer_Mercedes-B'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping variables with less variance in the data\n",
    "cars_new.drop(['Length', 'Width'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of variables and obs in the final data to be used for modelling\n",
    "cars_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data: separate out the feature/input/independant columns and dependant variable\n",
    "feature_columns = cars_new.columns.difference(['ln_sales_in_thousands', 'Sales_in_thousands'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1: divide the data into training and testing and separate out Y and X variables\n",
    "# this will be used in sklearn related functions\n",
    "train_X, test_X, train_y, test_y = train_test_split(cars_new[feature_columns], \n",
    "                                            cars_new['ln_sales_in_thousands'], test_size = 0.3, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2: divide the data into training and testing\n",
    "train, test = train_test_split(cars_new, test_size = 0.3, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the no of obs in training and testing after split\n",
    "print('No of obs in training: ', len(train), ' | ', 'No of obs in testing: ', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form of linear regression\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
    "\n",
    "- $y$ is the response\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for $x_1$ (the first feature)\n",
    "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature)\n",
    "\n",
    "The $\\beta$ values are called the **model coefficients**:\n",
    "\n",
    "- These values are estimated (or \"learned\") during the model fitting process using the **least squares criterion**.\n",
    "- Specifically, we are find the line (mathematically) which minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
    "- And once we've learned these coefficients, we can use the model to predict the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building a linear regression model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Steps for model building:\n",
    "------------------------------------------------------------------\n",
    "Step 1: lm = smf.ols('y~x1+x2+x3...xn', data = train) # defining Y and X with classs\n",
    "\n",
    "Step 2: lm.fit()     # building model (estimating the betas)\n",
    "\n",
    "Step 3: lm.summary() # get the output summary of the model\n",
    "\n",
    "Step 4: lm.predict(train) # predict the sales on the training data\n",
    "\n",
    "Step 5: lm.predict(test) # predict the sales on the testing/validation data\n",
    "\n",
    "Step 6: test the accuracy of the model\n",
    "    a.  MAPE: Mean Absolute Percentage Error\n",
    "    b.  RMSE: Root Mean Square Error\n",
    "    c.  Corelation between actual and predicted\n",
    "    d.  Decile analysis: for validation of models - Business validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 and Step 2: define Y, X and build a ols model\n",
    "lm1 = smf.ols('''ln_sales_in_thousands ~ Engine_size + Fuel_efficiency  + \n",
    "                    Manufacturer_Plymouth  + Price_in_thousands +\n",
    "                        Vehicle_type_Passenger + Wheelbase''', train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: get the output summary of the model\n",
    "print(lm1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: predict the sales on the training data\n",
    "train['pred_sales'] = np.exp(lm1.predict(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: predict the sales on the testing/validation data\n",
    "test['pred_sales'] = np.exp(lm1.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: accuracy metrics (a. MAPE: Mean Absolute Percentage Error)\n",
    "MAPE_train = np.mean(np.abs(train['Sales_in_thousands'] - train['pred_sales'])/train['Sales_in_thousands'])\n",
    "MAPE_test = np.mean(np.abs(test['Sales_in_thousands'] - test['pred_sales'])/test['Sales_in_thousands'])\n",
    "\n",
    "# print the values of MAPE for train and test\n",
    "print('MAPE of training data: ', MAPE_train,  ' | ', 'MAPE of testing data: ', MAPE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: accuracy metrics (d. Decile Analysis: for validation of models - Business validation)\n",
    "\n",
    "# create the 10 groups in the data\n",
    "train['Deciles'] = pd.qcut(train['pred_sales'], 10, labels = False)\n",
    "test['Deciles'] = pd.qcut(test['pred_sales'], 10, labels = False)\n",
    "\n",
    "# Decile Analysis for train data\n",
    "Predicted_avg = train[['Deciles', 'pred_sales']].groupby(train.Deciles).mean().sort_index(ascending = False)['pred_sales']\n",
    "Actual_avg = train[['Deciles', 'Sales_in_thousands']].groupby(train.Deciles).mean().sort_index(ascending = False)['Sales_in_thousands']\n",
    "Decile_analysis_train = pd.concat([Predicted_avg, Actual_avg], axis = 1).reset_index()\n",
    "\n",
    "# Decile Analysis for test data\n",
    "Predicted_avg = test[['Deciles', 'pred_sales']].groupby(test.Deciles).mean().sort_index(ascending = False)['pred_sales']\n",
    "Actual_avg = test[['Deciles', 'Sales_in_thousands']].groupby(test.Deciles).mean().sort_index(ascending = False)['Sales_in_thousands']\n",
    "Decile_analysis_test = pd.concat([Predicted_avg, Actual_avg], axis = 1).reset_index()\n",
    "\n",
    "# write the data into the file\n",
    "Decile_analysis_train.to_csv('Decile_analysis_train.csv')\n",
    "Decile_analysis_test.to_csv('Decile_analysis_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decile_analysis_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decile_analysis_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the independant variables for model creation\n",
    "model_param = 'ln_sales_in_thousands ~ ' + ' + '.join(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 and Step 2: define Y, X and build a ols model\n",
    "lm2 = smf.ols(model_param, train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: get the output summary of the model\n",
    "print(lm2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  VIF (Variance Inflation Factor): Check the multicollinieirity for all the variables in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High VIF of the variable means information in that variable has already been explained by \n",
    "# other X variables present in the model\n",
    "\n",
    "# import the packages for vif\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "# separate the Y and X variables\n",
    "y, X = dmatrices(model_param, train, return_type = 'dataframe')\n",
    "\n",
    "# For each X, calculate VIF and save in dataframe\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF Factor'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# display the output\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature selection based on importance using F - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection based on importance\n",
    "from sklearn.feature_selection import f_regression\n",
    "features = train_X\n",
    "target = train_y\n",
    "F_values, p_values  = f_regression(features, target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "f_reg_results = [(i, v, z) for i, v, z in itertools.zip_longest(features.columns, F_values,  ['%.3f' % p for p in p_values])]\n",
    "f_reg_results=pd.DataFrame(f_reg_results, columns=['Variable','F_Value', 'P_Value'])\n",
    "f_reg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_reg_results.sort_values(by = ['P_Value'])\n",
    "f_reg_results.P_Value = pd.to_numeric(f_reg_results.P_Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_reg_results_new = f_reg_results[f_reg_results.P_Value <= 0.1]\n",
    "f_reg_results_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If p - values are less, then variables are siginificant in the regression equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### execute the model on training and testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: predict the sales on the training data\n",
    "train['pred_sales'] = np.exp(lm2.predict(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: predict the sales on the testing/validation data\n",
    "test['pred_sales'] = np.exp(lm2.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model validation for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: accuracy metrics (a. MAPE: Mean Absolute Percentage Error)\n",
    "MAPE_train = '%.3f' % np.mean(np.abs(train.Sales_in_thousands - train.pred_sales)/train.Sales_in_thousands)\n",
    "MAPE_test = '%.3f' % np.mean(np.abs(test.Sales_in_thousands - test.pred_sales)/test.Sales_in_thousands)\n",
    "\n",
    "# print the values of MAPE for train and test\n",
    "print('MAPE of training data: ', MAPE_train,  ' | ', 'MAPE of testing data: ', MAPE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: accuracy metrics (b. RMSE: Root Mean Squared Error)\n",
    "RMSE_train = mean_squared_error(train.Sales_in_thousands ,train.pred_sales).round(3)\n",
    "RMSE_test = mean_squared_error(test.Sales_in_thousands ,test.pred_sales).round(3)\n",
    "\n",
    "# print the values of RMSE for train and test\n",
    "print('RMSE of training data: ', RMSE_train,  ' | ', 'RMSE of testing data: ', RMSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: accuracy metrics (c. Correlation)\n",
    "Corr_train = stats.stats.pearsonr(train.Sales_in_thousands, train.pred_sales)\n",
    "Corr_test = stats.stats.pearsonr(train.Sales_in_thousands, train.pred_sales)\n",
    "\n",
    "# print the values of Correlation for train and test\n",
    "print('Correlation of training data: ', Corr_train,  ' | ', 'Correlation of testing data: ', Corr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: accuracy metrics (d. Decile Analysis: for validation of models - Business validation)\n",
    "\n",
    "# create the 10 groups in the data\n",
    "train['Deciles'] = pd.qcut(train['pred_sales'], 10, labels = False)\n",
    "test['Deciles'] = pd.qcut(test['pred_sales'], 10, labels = False)\n",
    "\n",
    "# Decile Analysis for train data\n",
    "Predicted_avg = train[['Deciles', 'pred_sales']].groupby(train.Deciles).mean().sort_index(ascending = False)['pred_sales']\n",
    "Actual_avg = train[['Deciles', 'Sales_in_thousands']].groupby(train.Deciles).mean().sort_index(ascending = False)['Sales_in_thousands']\n",
    "Decile_analysis_train = pd.concat([Predicted_avg, Actual_avg], axis = 1).reset_index()\n",
    "\n",
    "# Decile Analysis for train data\n",
    "Predicted_avg = test[['Deciles', 'pred_sales']].groupby(test.Deciles).mean().sort_index(ascending = False)['pred_sales']\n",
    "Actual_avg = test[['Deciles', 'Sales_in_thousands']].groupby(test.Deciles).mean().sort_index(ascending = False)['Sales_in_thousands']\n",
    "Decile_analysis_test = pd.concat([Predicted_avg, Actual_avg], axis = 1).reset_index()\n",
    "\n",
    "# write the data into the file\n",
    "Decile_analysis_train.to_csv('Decile_analysis_train.csv')\n",
    "Decile_analysis_test.to_csv('Decile_analysis_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate the poor model performance due of LM assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assumption: Normality of the residuals/error (using distplot)\n",
    "sns.distplot(lm2.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: Normality of the residuals/error (using Q-Q plot)\n",
    "from scipy import stats\n",
    "import pylab\n",
    "\n",
    "stats.probplot(lm2.resid, dist = 'norm', plot = pylab)\n",
    "pylab.show()\n",
    "\n",
    "# If errors are normally and randomly distributed, they would be following a straight line pattern\n",
    "# Q-Q plot shows if the residuals are plotted along the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: mean of residuals/errors is zero\n",
    "print(lm2.resid.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: residuals/errors of the model should not be correlated with dependant (Y) variable\n",
    "print(stats.stats.pearsonr(lm2.resid, train.ln_sales_in_thousands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: homoscedasticity of residuals/errors\n",
    "sns.scatterplot(lm2.resid, train.ln_sales_in_thousands)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What can be the possible reasons for poor model performance?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Small sample \n",
    "2. Assumptions of linear/regression modelling are not true for the model in consideration\n",
    "2. Influential Observations (check this from QQ plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips/guidlines for imporvement of model accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Possible reasons for model is not validating (over fitting)\n",
    "---------------------------------------------------------------------------------------------\n",
    "1. Data preparation problem (outliers, missings, variable conversions etc. not correct)\n",
    "2. not included right variables\n",
    "3. If the data have multicollinerity\n",
    "4. Including more number of variables \n",
    "5. Data size is very low  (ideally we should have 1varaible = 100 obs)\n",
    "6. The assumptions are not 100% valid\n",
    "7. The variables are not explaining completely\n",
    "\n",
    "How to over come this problem?\n",
    "--------------------------------------------------------------------------------------------\n",
    "1. Increase the data/sample size\n",
    "2. Change the variables - Reiterate the model with different combinations of variables\n",
    "3. Apply right transformations on X variables such the the linear relationship between Y & X will imrpvove\n",
    "4. Add dervied variables which can explain Y better\n",
    "5. Re look into data preparation steps\n",
    "6. Look at the importance of variables include them in the model\n",
    "7. Change the modelling technique\n",
    "\n",
    "******************\n",
    "There are few techniques can help you to identify important variables (Variable selection - Feature selection)\n",
    "* F-Regression\n",
    "* RFE (Recursive feature elimination) - Stepwise regression\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Reading information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "How do we choose which features to include in the model? We're going to use **train/test split** (and eventually **cross-validation**).\n",
    "\n",
    "Why not use of **p-values** or **R-squared** for feature selection?\n",
    "\n",
    "- Linear models rely upon **a lot of assumptions** (such as the features being independent), and if those assumptions are violated, p-values and R-squared are less reliable. Train/test split relies on fewer assumptions.\n",
    "- Features that are unrelated to the response can still have **significant p-values**.\n",
    "- Adding features to your model that are unrelated to the response will always **increase the R-squared value**, and adjusted R-squared does not sufficiently account for this.\n",
    "- p-values and R-squared are **proxies** for our goal of generalization, whereas train/test split and cross-validation attempt to **directly estimate** how well the model will generalize to out-of-sample data.\n",
    "\n",
    "More generally:\n",
    "\n",
    "- There are different methodologies that can be used for solving any given data science problem, and this course follows a **machine learning methodology**.\n",
    "- This course focuses on **general purpose approaches** that can be applied to any model, rather than model-specific approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Accuracy\n",
    "> R-squared is a statistical measure of how close the data are to the fitted regression line. <br>\n",
    "> R-square signifies percentage of variations in the reponse variable that can be explained by the model. <br>\n",
    "> - R-squared = Explained variation / Total variation <br>\n",
    "> - Total variation is variation of response variable around it's mean. <br>\n",
    "\n",
    "> R-squared value varies between 0 and 100%. 0% signifies that the model explains none of the variability, <br>\n",
    "while 100% signifies that the model explains all the variability of the response. <br>\n",
    "The closer the r-square to 100%, the better is the model. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Evaluation metrics for regression problems\n",
    "\n",
    "Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. We need evaluation metrics designed for comparing **continuous values**.\n",
    "\n",
    "Here are three common evaluation metrics for regression problems:\n",
    "\n",
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing linear regression with other models\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain\n",
    "- Highly interpretable\n",
    "- Model training and prediction are fast\n",
    "- No tuning is required (excluding regularization)\n",
    "- Features don't need scaling\n",
    "- Can perform well with a small number of observations\n",
    "- Well-understood\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias\n",
    "- Can't automatically learn feature interactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
