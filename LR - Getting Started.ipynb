{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics to Discuss:\n",
    ">What is linear regression?<br>\n",
    ">Analyzing Advertisement dataset.<br>\n",
    ">Building a simple linear regression model & multiple linear regression model.<br>\n",
    ">Understanding OLS methods to estimate model parameters.<br>\n",
    ">How to use statsmodel API in python?<br>\n",
    ">Interpreting the coefficients of the model.<br>\n",
    ">How to find if the parameters estimated are significant?<br>\n",
    ">Making predictions using the model.<br>\n",
    ">Finding model residuals and analyzing it.<br>\n",
    ">Evaluating model efficiency using RMSE and R-Square values.<br>\n",
    ">Understanding gradient descent approach to find model parameters.<br>\n",
    ">Splitting dataseta and cross validating models.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adverstiment Dataset\n",
    ">The adverstiting dataset captures sales revenue generated with respect to advertisement spends across multiple channles \n",
    ">like radio, tv and newspaper.\n",
    "\n",
    "### Attribution Descriptions\n",
    ">TV - Spend on TV Advertisements <br>\n",
    ">Radio - Spend on radio Advertisements <br>\n",
    ">Newspaper - Spend on newspaper Advertisements <br>\n",
    ">Sales - Sales revenue generated <br>\n",
    "Note: The amounts are in diffrent units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import the packages and the data required for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages for charts/plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas profiling package\n",
    "import pandas_profiling as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "advt = pd.read_csv('D:/SampleData/Advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the metadata\n",
    "advt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas profiling report\n",
    "profile_report = pp.ProfileReport(advt)\n",
    "profile_report.to_file(output_file = 'profile_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first column\n",
    "advt = advt[['TV', 'Radio', 'Newspaper', 'Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create UDF - general function that returns multiple stats for continuous variables\n",
    "def var_summary(x):\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.sum(), x.mean(), x.median(),  \n",
    "                      x.std(), x.var(), x.min(), x.quantile(0.01), x.quantile(0.05),\n",
    "                          x.quantile(0.10),x.quantile(0.25),x.quantile(0.50),x.quantile(0.75), \n",
    "                              x.quantile(0.90),x.quantile(0.95), x.quantile(0.99),x.max()], \n",
    "                  index = ['N', 'NMISS', 'SUM', 'MEAN','MEDIAN', 'STD', 'VAR', 'MIN', 'P1', \n",
    "                               'P5' ,'P10' ,'P25' ,'P50' ,'P75' ,'P90' ,'P95' ,'P99' ,'MAX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data audit Report for continuous variables\n",
    "advt.loc[:, advt.dtypes == 'float64'].apply(lambda x: var_summary(x)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data cleaning/data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier treatment: cap all the numeric variables at 1% and 99%\n",
    "advt = advt.loc[:, advt.dtypes == 'float64'].apply(lambda x: x.clip(lower = x.quantile(0.01), upper = x.quantile(0.99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the %age of missing values in the data\n",
    "1 - advt.count()/advt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missings : fill with mean/median/mode\n",
    "# not required as no missings in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy variable creation\n",
    "# not required as no categorical variables in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exploratory data analysis : univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user defined function to create the distplots\n",
    "def fn_distplot(pd_series):\n",
    "    plt.figure(figsize = (5, 3))\n",
    "    sns.distplot(pd_series)\n",
    "    print('This is a chart for ' + pd_series.name)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dist plots for all float type variables\n",
    "advt.loc[:, advt.dtypes == 'float64'].apply(lambda x: fn_distplot(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "> 1. Sales seems to be normal distribution. \n",
    "> 2. Spending on newspaper advertisement seems to be righ skewed.\n",
    "> 3. Most of the spends on newspaper is fairly low where are spend on radio and tv seems be uniform distribution. \n",
    "> 4. Spends on tv are comparatively higher then spends on radio and newspaper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exploratory data analysis : bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user defined function to create the joint plots\n",
    "def fn_jointplot(y_variable, x_variable):\n",
    "    sns.jointplot(x_variable, y_variable, height = 5)\n",
    "    print('This is a chart for ' + y_variable.name + ' vs ' + x_variable.name)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is there a relationship between sales and spend various advertising channels?\n",
    "advt.loc[:, advt.dtypes == 'float64'].apply(lambda x: fn_jointplot(advt.Sales, x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    ">Sales and spend on newpaper is not highly correlaed where are sales and spend on tv is highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing pairwise correleation\n",
    "sns.pairplot(advt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corelation table : calculating correlations\n",
    "advt.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the correlations : the darker is the color, the stronger is the correlation\n",
    "sns.heatmap(advt.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "> 1. The diagonal of the above matirx shows the auto-correlation of the variables. It is always 1. \n",
    "> 2. You can observe that the correlation between TV and Sales is highest i.e. 0.78 and then between sales and radio i.e. 0.576.\n",
    "\n",
    "**Correlations can vary from -1 to +1.**\n",
    "<br/>\n",
    "**Closer to +1 means strong positive correlation and close -1 means strong negative correlation and closer to 0 means not correlated.**\n",
    "<br/>\n",
    "**variables with strong correlations are mostly probably candidates for model builing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Regression Model\n",
    "> 1. Linear regression is an approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. \n",
    "> 2. The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression\n",
    "> 3. A simple linear regression model is given by Y = mX + b\n",
    "<br/>\n",
    "> where m is the slope and b is the y-intercept. Y is the dependent variable and X is the explanatory variable. <br>\n",
    "\n",
    "**Very briefly and simplistically, Linear Regression is a class of techniques for fitting a straight line to a set of data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the package for ols modelling\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the variables in the data\n",
    "advt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "lm = smf.ols('Sales ~ TV', advt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model statistics\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "> Parameters estimated are considered to be significant if p-value is less than 0.05 <br>\n",
    "> This indicates TV is a significant parameters. And the parameter estimates can be accepted. <br><br>\n",
    "> <b>So, the linear model is</b> <br>\n",
    "> Sales = 7.1392 + 0.047 ∗ TV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Accuracy\n",
    "> R-squared is a statistical measure of how close the data are to the fitted regression line. <br>\n",
    "> R-square signifies percentage of variations in the reponse variable that can be explained by the model. <br>\n",
    "> R-squared = Explained variation / Total variation <br>\n",
    "> Total variation is variation of response variable around it's mean. <br>\n",
    "> R-squared value varies between 0 and 100%. 0% signifies that the model explains none of the variability, <br>\n",
    "> while 100% signifies that the model explains all the variability of the response. <br>\n",
    "> The closer the r-square to 100%, the better is the model. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions of the sales\n",
    "lmpredict = lm.predict(advt.TV)\n",
    "\n",
    "# give the name to the series\n",
    "lmpredict.name = 'Predicted Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original and the predicted values of the sales\n",
    "pd.concat([advt.Sales, lmpredict], axis = 1).round(2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating mean square error ... RMSE\n",
    "> RMSE calculate the difference between the actual value and predicted value of the response variable <br>\n",
    "> The square root of the mean/average of the square of all of the error. <br> \n",
    "> Compared to the similar Mean Absolute Error, RMSE amplifies and severely punishes large errors. <br>\n",
    "> The lesser the RMSE value, the better is the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the package\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate model accuracy : MSE (Mean Square Error)\n",
    "mse = metrics.mean_squared_error(advt.Sales, lmpredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate model accuracy : RMSE (Root Mean Square Error)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption check: residuals/errors should be normally distributed\n",
    "sns.distplot(lm.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One of the assumptions is that the residuals should be normally distributed i.e. it should be random.\n",
    "The residuals should be plotted against the response variable and it should not show any pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: residuals/errors of the model should not be correlated with dependant (Y) variable\n",
    "sns.jointplot(advt.Sales, lm.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "lm = smf.ols( 'Sales ~ TV + Radio', advt ).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model statistics\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "lmpredict = lm.predict(advt[['TV', 'Radio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original and the predicted values of the sales\n",
    "pd.concat([advt.Sales, lmpredict], axis = 1).round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate model accuracy : MSE (Mean Square Error)\n",
    "mse = metrics.mean_squared_error(advt.Sales, lmpredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate model accuracy : RMSE (Root Mean Square Error)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption check: residuals/errors should be normally distributed\n",
    "sns.distplot(lm.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One of the assumptions is that the residuals should be normally distributed i.e. it should be random.\n",
    "The residuals should be plotted against the response variable and it should not show any pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: residuals/errors of the model should not be correlated with dependant (Y) variable\n",
    "sns.jointplot(advt.Sales, lm.resid)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
